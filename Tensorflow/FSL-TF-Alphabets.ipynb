{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37bc09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# === Load dataset ===\n",
    "file_path = r\"C:\\Users\\JamJayDatuin\\Documents\\Machine Learning Projects\\TrainingAI-Models\\AlphabetSignLanguages\\FSL\\Alphabetical_hand_sign_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# === Prepare features and labels ===\n",
    "X = df.drop(\"label\", axis=1).values\n",
    "y = pd.Categorical(df[\"label\"]).codes  # convert A‚ÄìZ labels to numeric codes\n",
    "\n",
    "# === Split dataset ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === Define Keras model ===\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X.shape[1],)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(set(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# === Train model ===\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=25,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# === Evaluate model ===\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"‚úÖ Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "# === Ensure save directory exists ===\n",
    "SAVE_DIR = \"TFModels\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# === 1Ô∏è‚É£ Save in Keras format (for reloading in Python)\n",
    "keras_path = os.path.join(SAVE_DIR, \"FSL_Alphabet_TF_Model.keras\")\n",
    "model.save(keras_path)\n",
    "print(f\"üíæ Saved Keras model at: {keras_path}\")\n",
    "\n",
    "# === 2Ô∏è‚É£ Export as SavedModel (for TFLite conversion or mobile)\n",
    "export_dir = os.path.join(SAVE_DIR, \"FSL_Alphabet_TF_Model_SavedModel\")\n",
    "model.export(export_dir)\n",
    "print(f\"üìÇ Exported TensorFlow SavedModel at: {export_dir}\")\n",
    "\n",
    "# === 3Ô∏è‚É£ Convert SavedModel ‚Üí TensorFlow Lite (.tflite)\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_path = os.path.join(SAVE_DIR, \"FSL_Alphabet_TF_Model.tflite\")\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"üì¶ TensorFlow Lite model saved at: {tflite_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c36ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "# === Model paths ===\n",
    "KERAS_PATH = \"TFModels/FSL_Alphabet_TF_Model.keras\"\n",
    "SAVEDMODEL_PATH = \"TFModels/FSL_Alphabet_TF_Model_SavedModel\"\n",
    "TFLITE_PATH = \"TFModels/FSL_Alphabet_TF_Model.tflite\"\n",
    "\n",
    "# === Auto-detect model type ===\n",
    "USE_TFLITE = False\n",
    "USE_SAVEDMODEL = False\n",
    "\n",
    "if os.path.exists(KERAS_PATH):\n",
    "    try:\n",
    "        model = tf.keras.models.load_model(KERAS_PATH)\n",
    "        print(\"‚úÖ Loaded Keras model.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to load .keras model: {e}\")\n",
    "        USE_SAVEDMODEL = True\n",
    "elif os.path.exists(SAVEDMODEL_PATH):\n",
    "    try:\n",
    "        model = tf.keras.models.load_model(SAVEDMODEL_PATH)\n",
    "        print(\"‚úÖ Loaded SavedModel.\")\n",
    "        USE_SAVEDMODEL = True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to load SavedModel: {e}\")\n",
    "        USE_TFLITE = True\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Loading TensorFlow Lite model...\")\n",
    "    USE_TFLITE = True\n",
    "\n",
    "# === Setup TensorFlow Lite interpreter if needed ===\n",
    "if USE_TFLITE:\n",
    "    interpreter = tf.lite.Interpreter(model_path=TFLITE_PATH)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    print(\"‚úÖ Loaded TensorFlow Lite model.\")\n",
    "\n",
    "# === Mediapipe setup ===\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.7\n",
    ")\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# === Labels (A‚ÄìZ) ===\n",
    "labels = [chr(i) for i in range(65, 91)]\n",
    "\n",
    "# === Webcam setup ===\n",
    "cap = cv2.VideoCapture(0)\n",
    "history = deque(maxlen=10)\n",
    "\n",
    "# Keep track of last valid prediction\n",
    "last_prediction = \"No hands detected\"\n",
    "no_hand_counter = 0\n",
    "NO_HAND_THRESHOLD = 15   # number of frames before showing \"No hands detected\"\n",
    "\n",
    "print(\"üé• Starting real-time prediction... (Press ESC to exit)\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb)\n",
    "    current_prediction = None\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        no_hand_counter = 0  # reset if hand is detected\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            landmarks = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark]).flatten().reshape(1, -1)\n",
    "\n",
    "            try:\n",
    "                if USE_TFLITE:\n",
    "                    interpreter.set_tensor(input_details[0]['index'], landmarks.astype(np.float32))\n",
    "                    interpreter.invoke()\n",
    "                    output = interpreter.get_tensor(output_details[0]['index'])\n",
    "                else:\n",
    "                    output = model.predict(landmarks, verbose=0)\n",
    "\n",
    "                pred_idx = np.argmax(output)\n",
    "                current_prediction = labels[pred_idx] if pred_idx < len(labels) else \"?\"\n",
    "            except Exception as e:\n",
    "                current_prediction = f\"Error: {e}\"\n",
    "\n",
    "            history.append(current_prediction)\n",
    "    else:\n",
    "        # increment \"no hand\" counter\n",
    "        no_hand_counter += 1\n",
    "\n",
    "    # smooth prediction\n",
    "    if history:\n",
    "        smoothed_prediction = max(set(history), key=history.count)\n",
    "        if current_prediction:\n",
    "            last_prediction = smoothed_prediction\n",
    "        elif no_hand_counter > NO_HAND_THRESHOLD:\n",
    "            last_prediction = \"No hands detected\"\n",
    "\n",
    "    # display result\n",
    "    cv2.putText(frame, f\"Predicted: {last_prediction}\", (10, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"ASL Alphabet Recognition (TensorFlow)\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"üõë Stopped real-time prediction.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
